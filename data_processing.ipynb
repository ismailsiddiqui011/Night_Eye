{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Light to High Light Image Converter (Night Eye)\n",
    "### Problem Statement:\n",
    "- Predict a better lighting image from a given low/bad light image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import rawpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "img_w = 256\n",
    "img_h = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2697, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\short\\00001_00_0.04s.ARW</td>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\short\\00001_00_0.1s.ARW</td>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\short\\00001_01_0.04s.ARW</td>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\short\\00001_01_0.1s.ARW</td>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\short\\00001_02_0.1s.ARW</td>\n",
       "      <td>D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Low  \\\n",
       "0  D:\\Datasets\\Sony\\Sony\\short\\00001_00_0.04s.ARW   \n",
       "1   D:\\Datasets\\Sony\\Sony\\short\\00001_00_0.1s.ARW   \n",
       "2  D:\\Datasets\\Sony\\Sony\\short\\00001_01_0.04s.ARW   \n",
       "3   D:\\Datasets\\Sony\\Sony\\short\\00001_01_0.1s.ARW   \n",
       "4   D:\\Datasets\\Sony\\Sony\\short\\00001_02_0.1s.ARW   \n",
       "\n",
       "                                          High  \n",
       "0  D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW  \n",
       "1  D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW  \n",
       "2  D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW  \n",
       "3  D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW  \n",
       "4  D:\\Datasets\\Sony\\Sony\\long\\00001_00_10s.ARW  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirr = r'D:\\Datasets\\Sony\\Sony'\n",
    "low, high = [], []\n",
    "for file_y in os.listdir(r'D:\\Datasets\\Sony\\Sony\\long'):\n",
    "    for file_x in (os.listdir(r'D:\\Datasets\\Sony\\Sony\\short')):\n",
    "        if file_x.split('_')[0] == file_y.split('_')[0]:\n",
    "            low.append(os.path.join(dirr, 'short', file_x))\n",
    "            high.append(os.path.join(dirr, 'long', file_y))\n",
    "df = pd.DataFrame(data = {'Low': low, 'High': high})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_raw(raw):\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def patch_extract(im, x, y, divergence = 1):\n",
    "    im = im[y*divergence:y*divergence + img_w*divergence, x*divergence:x*divergence + img_w*divergence, :]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_dump_data(idx, subset):\n",
    "    low_image = rawpy.imread(df.Low.iloc[idx])\n",
    "    low_image = unpack_raw(low_image)\n",
    "    \n",
    "    high_image = rawpy.imread(df.High.iloc[idx])\n",
    "    high_image = high_image.postprocess()\n",
    "    \n",
    "    dirr = r'E:/Raw_Data/' + subset\n",
    "    np.save('{}/Low/{}'.format(dirr, df.Low.values[idx].split('\\\\')[-1][:-4] + '-' + str(idx+1)), low_image, allow_pickle = True)\n",
    "    np.save('{}/High/{}'.format(dirr, df.High.values[idx].split('\\\\')[-1][:-4] + '-' + str(idx+1)), high_image, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2427, 2), (675, 2), (270, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(df, test_size = 0.25)\n",
    "train, test = train_test_split(df, test_size = 0.10)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = Parallel(n_jobs = -1)(delayed(raw_dump_data)(idx, 'Train') for idx in (range(len(train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = Parallel(n_jobs = -1)(delayed(raw_dump_data)(idx, 'Val') for idx in (range(len(val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Parallel(n_jobs = -1)(delayed(raw_dump_data)(idx, 'Test') for idx in (range(len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_files_loc(dirr):\n",
    "    x,y=[],[]\n",
    "    for dirpath, _, files in os.walk(dirr): \n",
    "        for filename in files:\n",
    "            fname = os.path.join(dirpath,filename)\n",
    "            if len(re.findall('Low', dirpath)) != 0:\n",
    "                x.append(fname)\n",
    "            else:\n",
    "                y.append(fname)\n",
    "    df1 = pd.DataFrame({'Low': x, 'High':y})\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    arr = np.load(row[0], allow_pickle = True)\n",
    "    H = arr.shape[0]\n",
    "    W = arr.shape[1]\n",
    "    x = np.random.randint(0, W - img_w)\n",
    "    y = np.random.randint(0, H - img_h)\n",
    "    low = patch_extract(arr, x, y)\n",
    "\n",
    "    arr = np.load(row[1], allow_pickle = True)\n",
    "    H = arr.shape[0]\n",
    "    W = arr.shape[1]\n",
    "    high = patch_extract(arr, x, y, 2)\n",
    "    \n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_batch_data(dataframe, subset, batch_size = 32):\n",
    "    low_dir = r'D:/Batch_Data/{}/Low/'.format(subset)\n",
    "    high_dir = r'D:/Batch_Data/{}/High/'.format(subset)\n",
    "    for idx in tqdm(range(len(dataframe))):\n",
    "        X, Y = [], []\n",
    "        if str(idx) + '.npy' in os.listdir(low_dir):\n",
    "            pass\n",
    "\n",
    "        else: \n",
    "            batch_idx = np.random.choice(dataframe.index.values, size = batch_size)\n",
    "            rows = dataframe.iloc[batch_idx]\n",
    "            for row in rows.values:\n",
    "                temp = process(row)\n",
    "                X.append(temp[0])\n",
    "                Y.append(temp[1])\n",
    "            X = np.array(X)\n",
    "            Y = np.array(Y)\n",
    "            np.save(low_dir + '/{}.npy'.format(idx), X)\n",
    "            np.save(high_dir + '/{}.npy'.format(idx), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2258/2258 [1:30:28<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "train_df = fetch_files_loc(r'E:\\Raw_Data\\Train')\n",
    "dump_batch_data(train_df, 'Train', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 675/675 [34:50<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "val_df = fetch_files_loc(r'E:\\Raw_Data\\Val')\n",
    "dump_batch_data(val_df, 'Val', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [06:22<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "test_df = fetch_files_loc(r'E:\\Raw_Data\\Test')\n",
    "dump_batch_data(test_df, 'Test', 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
